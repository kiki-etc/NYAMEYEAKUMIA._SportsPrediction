{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, mean_absolute_error, r2_score\n",
    "import pickle as pkl\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Problem: FIFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pandas.read_csv(\"male_players (legacy).csv\")\n",
    "testing_data  = pandas.read_csv(\"players_22.csv\")\n",
    "\n",
    "training_data = training_data[['player_url','short_name','long_name','player_positions','potential','value_eur','wage_eur','age','dob','height_cm','weight_kg','club_team_id','club_name','league_name','league_level','club_position','club_jersey_number','club_loaned_from','nationality_id','nationality_name','nation_team_id','nation_position','nation_jersey_number','preferred_foot','weak_foot','skill_moves','international_reputation','work_rate','body_type','real_face','release_clause_eur','player_tags','player_traits','pace','shooting','passing','dribbling','defending','physic','attacking_crossing','attacking_finishing','attacking_heading_accuracy','attacking_short_passing','attacking_volleys','skill_dribbling','skill_curve','skill_fk_accuracy','skill_long_passing','skill_ball_control','movement_acceleration','movement_sprint_speed','movement_agility','movement_reactions','movement_balance','power_shot_power','power_jumping','power_stamina','power_strength','power_long_shots','mentality_aggression','mentality_interceptions','mentality_positioning','mentality_vision','mentality_penalties','mentality_composure','defending_marking_awareness','defending_standing_tackle','defending_sliding_tackle','goalkeeping_diving','goalkeeping_handling','goalkeeping_kicking','goalkeeping_positioning','goalkeeping_reflexes','goalkeeping_speed','ls','st','rs','lw','lf','cf','rf','rw','lam','cam','ram','lm','lcm','cm','rcm','rm','lwb','ldm','cdm','rdm','rwb','lb','lcb','cb','rcb','rb','gk','player_face_url','overall']]\n",
    "testing_data  = testing_data[ ['player_url','short_name','long_name','player_positions','potential','value_eur','wage_eur','age','dob','height_cm','weight_kg','club_team_id','club_name','league_name','league_level','club_position','club_jersey_number','club_loaned_from','nationality_id','nationality_name','nation_team_id','nation_position','nation_jersey_number','preferred_foot','weak_foot','skill_moves','international_reputation','work_rate','body_type','real_face','release_clause_eur','player_tags','player_traits','pace','shooting','passing','dribbling','defending','physic','attacking_crossing','attacking_finishing','attacking_heading_accuracy','attacking_short_passing','attacking_volleys','skill_dribbling','skill_curve','skill_fk_accuracy','skill_long_passing','skill_ball_control','movement_acceleration','movement_sprint_speed','movement_agility','movement_reactions','movement_balance','power_shot_power','power_jumping','power_stamina','power_strength','power_long_shots','mentality_aggression','mentality_interceptions','mentality_positioning','mentality_vision','mentality_penalties','mentality_composure','defending_marking_awareness','defending_standing_tackle','defending_sliding_tackle','goalkeeping_diving','goalkeeping_handling','goalkeeping_kicking','goalkeeping_positioning','goalkeeping_reflexes','goalkeeping_speed','ls','st','rs','lw','lf','cf','rf','rw','lam','cam','ram','lm','lcm','cm','rcm','rm','lwb','ldm','cdm','rdm','rwb','lb','lcb','cb','rcb','rb','gk','player_face_url','overall']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaning the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manually dropping columns with irrelevant data because they, intuitively, bare no correlation with a player's rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.drop(columns=['player_url','short_name','long_name','dob','club_team_id','club_name','league_name','league_level','club_position','club_jersey_number','club_loaned_from','nationality_id','nationality_name','nation_team_id','nation_position','nation_jersey_number','real_face','release_clause_eur','player_tags','player_traits','player_face_url'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop columns that have over 30% null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = (training_data.isnull().sum()/len(training_data))\n",
    "drop = percentage[percentage > 0.3].index\n",
    "training_data.drop(columns=drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = training_data.filter(items=['ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lam', 'cam', 'ram',\n",
    "                                    'lm', 'lcm', 'cm', 'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb',\n",
    "                                    'lb', 'lcb', 'cb', 'rcb', 'rb', 'gk'])\n",
    "\n",
    "def convert_to_number(entry):\n",
    "    if '+' in entry:\n",
    "        parts = entry.split('+')\n",
    "        return int(parts[0]) + int(parts[1])\n",
    "    elif '-' in entry:\n",
    "        parts = entry.split('-')\n",
    "        return int(parts[0]) - int(parts[1])\n",
    "    else:\n",
    "        return int(entry)\n",
    "\n",
    "filtered = filtered.applymap(convert_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.update(filtered)\n",
    "int_columns = ['ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lam', 'cam', 'ram',\n",
    "                'lm', 'lcm', 'cm', 'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb',\n",
    "                'lb', 'lcb', 'cb', 'rcb', 'rb', 'gk']\n",
    "\n",
    "training_data[int_columns] = training_data[int_columns].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric      = training_data.select_dtypes(include=numpy.number)\n",
    "non_numeric  = training_data.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imputing the missing numerical values with the **mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_with_NaN = numeric.columns[numeric.isnull().any().tolist()]\n",
    "\n",
    "for column in numeric_with_NaN:\n",
    "   numeric[column].fillna(numeric[column].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replacing NaN `object` values with the **mode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_with_NaN = non_numeric.columns[non_numeric.isnull().any().tolist()]\n",
    "\n",
    "for column in non_numeric_with_NaN:\n",
    "  non_numeric[column].fillna(non_numeric[column].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**encoding** for non-numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for column in non_numeric:\n",
    "  non_numeric[column] = label_encoder.fit_transform(non_numeric[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concatenating to form the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pandas.concat([non_numeric, numeric], axis=1)\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function for cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def clean_player_data(data):\n",
    "    \"\"\"\n",
    "    The `clean_player_data` function takes a DataFrame as a parameter and returns a DataFrame with the clean data (no missing values and non-numeric data is encoded). It only works if the column data is similar, so the following columns need to be present: ['player_url','short_name','long_name','player_positions','potential','value_eur','wage_eur','age','dob','height_cm','weight_kg','club_team_id','club_name','league_name','league_level','club_position','club_jersey_number','club_loaned_from','nationality_id','nationality_name','nation_team_id','nation_position','nation_jersey_number','preferred_foot','weak_foot','skill_moves','international_reputation','work_rate','body_type','real_face','release_clause_eur','player_tags','player_traits','pace','shooting','passing','dribbling','defending','physic','attacking_crossing','attacking_finishing','attacking_heading_accuracy','attacking_short_passing','attacking_volleys','skill_dribbling','skill_curve','skill_fk_accuracy','skill_long_passing','skill_ball_control','movement_acceleration','movement_sprint_speed','movement_agility','movement_reactions','movement_balance','power_shot_power','power_jumping','power_stamina','power_strength','power_long_shots','mentality_aggression','mentality_interceptions','mentality_positioning','mentality_vision','mentality_penalties','mentality_composure','defending_marking_awareness','defending_standing_tackle','defending_sliding_tackle','goalkeeping_diving','goalkeeping_handling','goalkeeping_kicking','goalkeeping_positioning','goalkeeping_reflexes','goalkeeping_speed','ls','st','rs','lw','lf','cf','rf','rw','lam','cam','ram','lm','lcm','cm','rcm','rm','lwb','ldm','cdm','rdm','rwb','lb','lcb','cb','rcb','rb','gk','player_face_url','overall']\n",
    "    data: the DataFrame with similar column headings to the `players_22.csv` dataset\n",
    "    \"\"\"\n",
    "    data.drop(columns=['player_url', 'short_name', 'long_name', 'dob', 'club_team_id', 'club_name', 'league_name', \n",
    "                       'league_level', 'club_position', 'club_jersey_number', 'club_loaned_from', 'nationality_id', \n",
    "                       'nationality_name', 'nation_team_id', 'nation_position', 'nation_jersey_number', 'real_face', \n",
    "                       'release_clause_eur', 'player_tags', 'player_traits', 'player_face_url'], inplace=True)\n",
    "\n",
    "    # drop columns with more than 30% missing values\n",
    "    percentage = (data.isnull().sum() / len(data))\n",
    "    drop = percentage[percentage > 0.3].index\n",
    "    data.drop(columns=drop, inplace=True)\n",
    "\n",
    "    int_columns = ['ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lam', 'cam', 'ram',\n",
    "                   'lm', 'lcm', 'cm', 'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb',\n",
    "                   'lb', 'lcb', 'cb', 'rcb', 'rb', 'gk']\n",
    "    filtered_columns = data.filter(items=int_columns)\n",
    "\n",
    "    def convert_to_int(entry):\n",
    "        entry = str(entry)  # Convert entry to string\n",
    "        if '+' in entry:\n",
    "            parts = entry.split('+')\n",
    "            return int(parts[0]) + int(parts[1])\n",
    "        elif '-' in entry:\n",
    "            parts = entry.split('-')\n",
    "            return int(parts[0]) - int(parts[1])\n",
    "        else:\n",
    "            return int(entry)\n",
    "\n",
    "    filtered_columns = filtered_columns.applymap(convert_to_int)\n",
    "\n",
    "    # update data with converted columns\n",
    "    data.update(filtered_columns)\n",
    "    data[int_columns] = data[int_columns].astype(int)\n",
    "\n",
    "    numeric_data = data.select_dtypes(include=np.number)\n",
    "    non_numeric_data = data.select_dtypes(include=['object'])\n",
    "\n",
    "    # fill missing values in numeric columns with mean\n",
    "    numeric_NaN = numeric_data.columns[numeric_data.isnull().any()].tolist()\n",
    "    for column in numeric_NaN:\n",
    "        numeric_data[column].fillna(numeric_data[column].mean(), inplace=True)\n",
    "\n",
    "    # fill missing values in non-numeric columns with mode\n",
    "    non_numeric_NaN = non_numeric_data.columns[non_numeric_data.isnull().any()].tolist()\n",
    "    for column in non_numeric_NaN:\n",
    "        non_numeric_data[column].fillna(non_numeric_data[column].mode()[0], inplace=True)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    for column in non_numeric_data:\n",
    "        non_numeric_data[column] = label_encoder.fit_transform(non_numeric_data[column])\n",
    "\n",
    "    return pd.concat([non_numeric_data, numeric_data], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleaning the testing data using the `clean_player_data` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = clean_player_data(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Using the RandomForest classifier to decide which features are the most important, as opposed to the correlation matrix, which may be too simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Ytrain = training_data.drop('overall',axis=1), training_data['overall']\n",
    "Xtest,  Ytest  = testing_data.drop('overall',axis=1),  testing_data['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rforest = RandomForestRegressor(n_estimators=110, random_state=45, max_depth=15, criterion='absolute_error')\n",
    "rforest.fit(Xtrain, Ytrain)\n",
    "\n",
    "feature_importances = rforest.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df = pd.DataFrame({'Feature': Xtrain.columns, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "feature_importance_df.iloc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comparing with correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pd.DataFrame(training_data.corr())\n",
    "corr['overall'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = ['movement_reactions', 'mentality_composure', 'power_shot_power', 'cm', 'mentality_vision',\n",
    "                     'value_eur', 'age', 'potential', 'gk', 'wage_eur', 'overall']\n",
    "\n",
    "Xtrain = training_data[selected]\n",
    "Xtest  = testing_data[selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "Xtrain_scaled = scaler.fit_transform(Xtrain)\n",
    "Xtest_scaled  = scaler.fit_transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the ensemble models\n",
    "Picking three ensemble models, then tuning the hyper parameters to get the best predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor()\n",
    "\n",
    "gbr.fit(Xtrain, Ytrain)\n",
    "gbr_initial = gbr.predict(Xtest)\n",
    "\n",
    "print(f\"\"\"MAE:  {mean_absolute_error(gbr_initial, Ytest)}\n",
    "MSE:  {mean_squared_error(gbr_initial, Ytest)}\n",
    "RMSE: {numpy.sqrt(mean_squared_error(gbr_initial, Ytest))}\n",
    "R2 =  {r2_score(gbr_initial, Ytest)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_parameters = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.1, 0.05]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_gb = GridSearchCV(estimator=gbr, param_grid=gbr_parameters, cv=kf, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search_gb.fit(Xtrain, Ytrain)\n",
    "\n",
    "gbr_best_parameters = grid_search_gb.best_params_\n",
    "\n",
    "# training with best parameters\n",
    "best_gbr = GradientBoostingRegressor(**gbr_best_parameters, random_state=42)\n",
    "best_gbr.fit(Xtrain, Ytrain)\n",
    "\n",
    "# prediction and evaluation\n",
    "y_pred_gbr = best_gbr.predict(Xtest)\n",
    "print(f\"\"\"MAE:  {mean_absolute_error(y_pred_gbr, Ytest)}\n",
    "MSE:  {mean_squared_error(y_pred_gbr, Ytest)}\n",
    "RMSE: {numpy.sqrt(mean_squared_error(y_pred_gbr, Ytest))}\n",
    "R2 =  {r2_score(y_pred_gbr, Ytest)}\"\"\")\n",
    "\n",
    "gbr_evaluator = numpy.sqrt(mean_squared_error(y_pred_gbr, Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Adaptive Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostRegressor()\n",
    "\n",
    "ada.fit(Xtrain, Ytrain)\n",
    "ada_initial = ada.predict(Xtest)\n",
    "\n",
    "print(f\"\"\"MAE:  {mean_absolute_error(ada_initial, Ytest)}\n",
    "MSE:  {mean_squared_error(ada_initial, Ytest)}\n",
    "RMSE: {numpy.sqrt(mean_squared_error(ada_initial, Ytest))}\n",
    "R2 =  {r2_score(ada_initial, Ytest)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_parameters = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [1.0, 0.5, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_ada = GridSearchCV(estimator=ada, param_grid=ada_parameters, cv=kf, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search_ada.fit(Xtrain, Ytrain)\n",
    "\n",
    "ada_best_parameters = grid_search_ada.best_params_\n",
    "\n",
    "# training with best parameters\n",
    "best_ada = GradientBoostingRegressor(**ada_best_parameters, random_state=42)\n",
    "best_ada.fit(Xtrain, Ytrain)\n",
    "\n",
    "# prediction and evaluation\n",
    "y_pred_ada = best_ada.predict(Xtest)\n",
    "print(f\"\"\"MAE:  {mean_absolute_error(y_pred_ada, Ytest)}\n",
    "MSE:  {mean_squared_error(y_pred_ada, Ytest)}\n",
    "RMSE: {numpy.sqrt(mean_squared_error(y_pred_ada, Ytest))}\n",
    "R2 =  {r2_score(y_pred_ada, Ytest)}\"\"\")\n",
    "\n",
    "ada_evaluator = numpy.sqrt(mean_squared_error(y_pred_ada, Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Histogram Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgb = HistGradientBoostingRegressor()\n",
    "\n",
    "hgb.fit(Xtrain, Ytrain)\n",
    "hgb_initial = hgb.predict(Xtest)\n",
    "\n",
    "print(f\"\"\"MAE:  {mean_absolute_error(hgb_initial, Ytest)}\n",
    "MSE:  {mean_squared_error(hgb_initial, Ytest)}\n",
    "RMSE: {numpy.sqrt(mean_squared_error(hgb_initial, Ytest))}\n",
    "R2 =  {r2_score(hgb_initial, Ytest)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgb_parameters = {\n",
    "    'learning_rate': [1.0, 0.5, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_hgb = GridSearchCV(estimator=hgb, param_grid=hgb_parameters, cv=kf, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search_hgb.fit(Xtrain, Ytrain)\n",
    "\n",
    "hgb_best_parameters = grid_search_hgb.best_params_\n",
    "\n",
    "# training with best parameters\n",
    "best_hgb = GradientBoostingRegressor(**hgb_best_parameters, random_state=42)\n",
    "best_hgb.fit(Xtrain, Ytrain)\n",
    "\n",
    "# prediction and evaluation\n",
    "y_pred_hgb = best_hgb.predict(Xtest)\n",
    "print(f\"\"\"MAE:  {mean_absolute_error(y_pred_hgb, Ytest)}\n",
    "MSE:  {mean_squared_error(y_pred_hgb, Ytest)}\n",
    "RMSE: {numpy.sqrt(mean_squared_error(y_pred_hgb, Ytest))}\n",
    "R2 =  {r2_score(y_pred_hgb, Ytest)}\"\"\")\n",
    "\n",
    "hgb_evaluator = numpy.sqrt(mean_squared_error(y_pred_hgb, Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluators = [gbr_evaluator, ada_evaluator, hgb_evaluator]\n",
    "minimum_rmse = min(evaluators)\n",
    "\n",
    "if minimum_rmse == gbr_evaluator:\n",
    "    best_model  = best_gbr\n",
    "    best_params = gbr_best_parameters\n",
    "elif minimum_rmse == ada_evaluator:\n",
    "    best_model  = best_ada\n",
    "    best_params = ada_best_parameters\n",
    "else:\n",
    "    best_model  = best_hgb\n",
    "    best_params = hgb_best_parameters\n",
    "\n",
    "y_pred_test = best_model.predict(Xtest)\n",
    "mse_test = mean_squared_error(Ytest, y_pred_test)\n",
    "\n",
    "print(f\"\"\"Best Model:           {best_model}\n",
    "Best Hyperparameters: {best_params}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model (`.pkl` file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(best_model, open(best_model.__class__.__name__ + '.pkl', 'wb'))\n",
    "joblib.dump(scaler, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
